# Лабораторная работа №3

Данная лабораторная работа предполагает расширение полученных 
знаний детектирования (классификации) неизвестного текста.
Для этого будет использоваться новый способ представления текста в виде N-грамм.

## Дано

1. Три текста на английском, немецком и неизвестном языках.
2. Необходимо определить, на каком языке написан последний текст.

**_Важно:_** в файле `start.py` вы должны написать код, определяющий язык неизвестного текста. 
Для этого реализуйте функции в модуле `main.py` и импортируйте их в `start.py`.
Весь код, выполняющий детектирование языка, должен быть выполнен в блоке `__main__:`.

В рамках данной лабораторной работы **НЕЛЬЗЯ использовать сторонние модули и модуль collections.**

## Терминология

В рамках данной работы вы будете работать с N-граммами.

N-грамма - это последовательность из n элементов, в настоящей работе - 
последовательность из n букв.

Один элемент - униграмма.

Последовательность из двух элементов - биграмма.

Последовательность из трех элементов - триграмма.

Последовательность из четырех и более элементов обозначается как N-грамма,
где N заменяется на количество последовательных элементов.

Например, `word = 'sunny'`, `unigrams = ['s', 'u', 'n', 'n', 'y']`,
`bigrams = ['su', 'un', 'nn', 'ny']`, `trigrams = ['sun', 'unn', 'nny']`.

**_Важно:_** вам необходимо уметь собирать следующие N-граммы на определенные оценки:

- 6 - биграммы
- 8 - триграммы
- 10 - N-граммы

## Ход работы

В рамках лабораторной работы №3 требуется разобрать алгоритм извлечения
N-грамм из текста и использовать их для определения языка произвольного текста.

### Шаг 1. Разбить исходный текст на предложения и токены

Функция разбивает заданный текст на предложения и возвращает кортеж
предложений с токенами.

В качестве разделителя используется завершающий пунктуационный знак, пробел.

Каждое предложение токенизируется и разбивается по буквам. Все строки (буквы)
в нижнем регистре, не содержат знаков пунктуации, в том числе и завершающий
знак препинания.

Каждый токен (например, `she` в примере ниже) также содержит специальные
символы начала (`_`) и конца слова (`_`). Вставка этих символов 
обязательна для корректной работы алгоритма в дальнейшем.

Если на вход подаются некорректные значения, возвращается пустой кортеж.

Например,
```py
input_text = 'She is happy. He is happy.' 

output_text = (
         (('_', 's', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_')),
         (('_', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_'))
)
```

**Интерфейс**:
```py
def tokenize_by_sentence(text: str) -> tuple:
    pass
```

### Шаг 2. Создание хранилища соответствий буква-число

Каждой букве из заданного текста присваивается некоторый уникальный идентификатор
`id`. Это требуется для того, чтобы работать не со строками напрямую, а с числами,
которые их представляют.

Например, букве `'a'` ставим в соответствие некоторое уникальное 
число - `1`. Следующей букве `'c'` - `2` и так далее.
Эти буквы необходимо поместить в поле `storage` класса `LetterStorage`,
ключом хранилища является буква, а значением – её идентификатор.
Буквы, указанные выше, будут храниться следующим образом:

```py
self.storage = {..., 'a': 1, 'c': 2, ...}
```

Для хранения букв и их идентификаторов необходимо создать поле класса - `storage`.  

**Интерфейс**:

```py
class LetterStorage:
    pass
```

### Шаг 2.1. Добавление буквы в хранилище

Метод принимает на вход букву и добавляет её в хранилище `storage`.

Правило для присваивания 
идентификатора - порядковое присваивание (счетчик, начинающийся с единицы). 
Основное условие - для одной и той же буквы существует ровно один идентификатор.
Одинаковых идентификаторов у двух разных букв быть не может.

Если буква была добавлена в хранилище или уже существовала в нем, возвращается `0`.
При этом если буква уже существовала в хранилище, идентификатор остается прежним.

Если на вход подается некорректное значение, возвращается `-1`.
Пустая строка считается **некорректным** значением.

**Интерфейс**:

```py
class LetterStorage:
  ...
  def _put_letter(self, letter: str) -> int:
    pass
```

### Шаг 2.2. Получения идентификатора буквы

Метод принимает на вход букву и возвращает её идентификатор.

Если на вход подается неизвестная буква, возвращается `-1`.

**Интерфейс**:

```py
class LetterStorage:
  ...
  def get_id_by_letter(self, letter: str) -> int:
    pass
```

### Шаг 2.3. Получения буквы по идентификатору

Метод принимает на вход идентификатор и возвращает соответствующую букву.

Если на вход подается неизвестный или некорректный идентификатор, возвращается `-1`.

**Интерфейс**:

```py
class LetterStorage:
  ...
  def get_letter_by_id(self, letter_id: int) ->str or int:
    pass
```

### Шаг 2.4. Заполнение хранилища буквами из корпуса предложений

Метод заполняет хранилище-словарь `self.storage` 
класса `LetterStorage` буквами из кортежа предложений.

Например,
```py
corpus = (
         (('_', 's', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_')),
         (('_', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_'))
         )
```

Если добавление прошло успешно, возвращается `0`.
Если на вход подается некорректное значение, возвращается `-1`.

**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать метод `_put_letter`.

**Интерфейс**:

```py
class LetterStorage:
  ...
  def update(self, corpus: tuple) -> int:
    pass
```

### Шаг 3. Кодирование корпуса предложений

Функция кодирует корпус предложений, используя заполненный экземпляр 
класса `LetterStorage`, и возвращает кортеж закодированных предложений.
Кодирование заключается в замене букв на соответствующие идентификаторы.

Например для заданного корпуса, 
```py
input_corpus = (
         (('_', 's', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_')),
         (('_', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_'))
         )
```
Будет получен следующий закодированный корпус:
```py
encoded_corpus = (
                  ((1, 2, 3, 4, 1), (1, 5, 2, 1), (1, 3, 6, 7, 7, 8, 1)),
                  ((1, 3, 4, 1), (1, 5, 2, 1), (1, 3, 6, 7, 7, 8, 1))
                  )
```

Если на вход подаются некорректные значения, возвращается пустой кортеж.

**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать метод `get_id_by_letter`.

**Интерфейс**:

```py
def encode_corpus(storage: LetterStorage, corpus: tuple) -> tuple:
  pass
```

### Шаг 4. Декодирование корпуса предложений (Выполнение шагов 1-4 соответствует 4 баллам)

Функция декодирует корпус предложений, используя заполненный экземпляр класса `LetterStorage`,
и возвращает кортеж исходных предложений.
Декодирование заключается в замене идентификаторов на соответствующие буквы.
Работа данной функции противоположна работе функции `encode_corpus`.

Например для заданного закодированного текста, 
```py
input_corpus = (
  ((1, 2, 3, 4, 1), (1, 5, 2, 1), (1, 3, 6, 7, 7, 8, 1)),
  ((1, 3, 4, 1), (1, 5, 2, 1), (1, 3, 6, 7, 7, 8, 1))
)
```
Будет получен следующий декодированный текст:
```py
decoded_corpus = (
  (('_', 's', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_')),
  (('_', 'h', 'e', '_'), ('_', 'i', 's', '_'), ('_', 'h', 'a', 'p', 'p', 'y', '_'))
)
```

Если на вход подаются некорректные значения, возвращается пустой кортеж.

**Дополнительные требования:**

1. В данной функции ОБЯЗАТЕЛЬНО использовать метод `get_letter_by_id`.

**Интерфейс**:

```py
def decode_corpus(storage: LetterStorage, corpus: tuple) -> tuple:
  pass
```

### Шаг 5. Создать структуру для хранения и обработки N-грамм

Класс `NGramTrie` позволяет собрать N-граммы из 
заданного закодированного предложения или текста.

> Это не опечатка в названии класса. 
> Такое название выбрано намеренно (trie является отраслевым термином).

Допустим, закодированный текст выглядит следующим образом: 
`text = (((1, 2, 3, 1), (1, 4, 5, 1), (1, 2, 6, 7, 7, 8, 1)),)`

1. Например, если нам необходимо заполнить NGramTrie с n, равным 2,
то мы получим следующие биграммы:
`((((1, 2), (2, 3), (3, 1)), ((1, 4), (4, 5), (5, 1)), ((1, 2), (2, 6), (6, 7), (7, 7), (7, 8), (8, 1))),)`

2. Например, если нам необходимо заполнить NGramTrie с n, равным 3,
то мы получим следующие триграммы:
`((((1, 2, 3), (2, 3, 1)), ((1, 4, 5), (4, 5, 1)), ((1, 2, 6), (2, 6, 7), (6, 7, 7), (7, 7, 8), (7, 8, 1))),)`

### Шаг 5.1. Объявить сущность языковой модели

Создадим класс:

```py
class NGramTrie:
    pass
```

Конструктор принимает на вход размер N-граммы `n`. Это значение
сохраняется в собственном поле экземпляра класса - `self.size`. 

Конструктор также принимает экземпляр класса хранилища `LetterStorage`.
Это значение сохраняется в собственном поле экземпляра класса - `self.storage`.

Сами N–граммы хранятся (после расчета) в поле экземпляра класса – `self.n_grams`.

Также, в конструкторе присутствует поле `self.n_gram_frequencies`,
в котором хранятся N-граммы и их частоты в виде словаря.

Например, при инициализации класса `NGramTrie` c хранилищем букв и размером N-грамм равным 2,
конструктор будет выглядеть следующим образом:
```py
ngrams = NGramTrie(letter_storage_object, 2)
print(ngrams.size) # 2
print(ngrams.storage) # LetterStorage class instance
print(ngrams.ngrams) # []
print(ngrams.n_gram_frequencies) # {}
```

### Шаг 5.2. Извлечь N-граммы из закодированного корпуса

Метод принимает на вход закодированный корпус, извлекает N-граммы
(размер N-грамм хранится в поле `self.size`) и заполняет поле `self.n_grams`.

> Для студентов, желающих получить оценку 6, на данном этапе 
> достаточно реализовать только биграммы.

Если добавление прошло успешно, возвращается `0`.
Если на вход подается некорректное значение, возвращается `1`.

Например, для заданного текста, при работе с биграммами:
```py
input_text = (((1, 2, 3, 1), (1, 4, 5, 1), (1, 2, 6, 7, 7, 8, 1)),)
```
Метод заполнит поле `self.ngrams` следующими биграмами:
```py
print(self.ngrams) # ((((1, 2), (2, 3), (3, 1)), ((1, 4), (4, 5), (5, 1)), ((1, 2), (2, 6), (6, 7), (7, 7), (7, 8), (8, 1))),)
```

**Интерфейс**:
```py
class NGramTrie:
  ...
  def extract_n_grams(self, encoded_corpus: tuple) -> int:
      pass
```

### Шаг 5.3. Получить самые частотные N-граммы

Метод получает частотные N-граммы используя поле `self.n_grams`.
Метод заполняет поле `self.n_gram_frequencies`.

Если добавление прошло успешно, возвращается 0.
Если на вход подается некорректное значение, возвращается 1.

Например, при следующих N-граммах в поле `self.ngrams`:
```py
print(self.ngrams) # ((((1, 2), (2, 3), (3, 1)), ((1, 4), (4, 5), (5, 1)), ((1, 2), (2, 6), (6, 7), (7, 7), (7, 8), (8, 1))),)
```
По результатам вызова текущего метода будет заполнено
поле `self.n_gram_frequencies` следующим образом:
```py
print(self.n_gram_frequencies) # {(1, 2): 2, (2, 3): 1, (3, 1): 1, (1, 4): 1, (4, 5): 1, (5, 1): 1, (2, 6): 1, (6, 7): 1, (7, 7): 1, (7, 8): 1, (8, 1): 1}
```

**Интерфейс**:
```py
class NGramTrie:
  ...
  def get_n_grams_frequencies(self) -> int:
      pass
```

### Шаг 6. Создать структуру для представления языкового профиля

Создадим класс:

```py
class LanguageProfile:
    pass
```

Конструктор принимает на вход экземпляр класса хранилища `LetterStorage`. 
Это значение сохраняется в собственном поле экземпляра класса - `self.storage`.

Конструктор также принимает на вход метку языка, для которого будет создаваться
языковой профиль `language_name`. Это значение сохраняется в собственном поле 
экземпляра класса `self.language`.

Помимо заполняемых при инициализации класса полей, у класса `LanguageProfile`
также присутствуют поля, которые будут заполнены при дальнейшей работе с классом:

- `self.tries` - список из объектов класса `NGramTrie`, в которых хранятся N-граммы
    для языкового профиля
- `self.n_words` - список количества каждого вида N-грамм по порядку, участвующих в построении
    языкового профиля. Например, если дано 20 биграмм и 35 4-грамм, список будет выглядеть следующим образом: `[20, 35]`,
    23 униграммы, 11 триграмм и 5 четыреграмм - `[23, 11, 5]`.
    
Например, при инициализации класса `LanguageProfile` c хранилищем букв и меткой языка `en`,
конструктор будет выглядеть следующим образом:
```py
en_profile = LanguageProfile(letter_storage_object, 'en')
print(en_profile.storage) # LetterStorage class instance
print(en_profile.language) # `en`
print(en_profile.tries) # []
print(en_profile.n_words) # []
```

### Шаг 6.1. Заполнить языковой профиль

Метод принимает на вход закодированный текст `encoded_corpus`, 
а также кортеж с размерностями N-грамм `ngram_sizes`.

Метод создает языковой профиль. 
Для каждой размерности N-граммы из кортежа `ngram_sizes`
создается и заполняется N-граммами экземпляр класса `NGramTrie`,
а затем этот экземпляр помещается в соответствующее поле класса `self.tries`.

Также, для каждой размерности N-граммы из кортежа `ngram_sizes`
также считается число N-грамм этой размерности (сумма) и
помещается в поле класса `self.n_words`.

Например, для заданного закодированного корпуса:
```py
encoded_corpus = (((1, 2, 3, 1), (1, 4, 5, 1), (1, 2, 6, 7, 7, 8, 1)),)
```
Поля `self.tries` и `self.n_words` заполнятся следующим образом:
```py
print(self.tries) # [<__main__.NGramTrie object at 0x09DB9BB0>, <__main__.NGramTrie object at 0x09DB9A48>]
print(self.n_words) # [11, 9]
```

**Обратите внимание**, что поле `self.tries` хранит именно экземпляры класса `NGramTrie` и
мы можем получить желаемые биграммы или триграммы, обратившись к
соответствующему экземпляру класса `NGramTrie` из списка `self.tries`:
```py
print(self.tries[0].n_grams) # ((((1, 2), (2, 3), (3, 1)), ((1, 4), (4, 5), (5, 1)), ((1, 2), (2, 6), (6, 7), (7, 7), (7, 8), (8, 1))),)
```
 
Метод возвращает `0`, если заполнение обозначенных полей прошло успешно
и возвращает `1` в противном случае.

**Интерфейс**:
```py
class LanguageProfile:
  ...
  def create_from_tokens(self, encoded_corpus: tuple, ngram_sizes: tuple) -> int:
      pass
```

### Шаг 6.2. Получить топ k самых частотных N-грамм

Метод получает на вход параметр `k` - число самых частотных N-грамм.

Метод также получает параметр `trie_level` - размерность N-граммы,
например, 2 - биграммы, 3 - триграммы.

Метод возвращает кортеж из `k` самых частотных N-грамм.

Например, для заданного закодированного текста и существующего профиля
с `self.tries` с 2-3-граммами. При параметре `k` = 3 и параметре `trie_level` = 2, а затем 3:
```py
encoded_corpus = (((1, 2, 3, 1), (1, 4, 5, 1), (1, 2, 6, 7, 7, 8, 1)),)
print(self.tries) # [<__main__.NGramTrie object at 0x09DB9BB0>, <__main__.NGramTrie object at 0x09DB9A48>]
```
Будут получены следующие 3 самых частотных 2-3-граммы соответственно:
```py
print(top_3_bi_grams) # ((1, 2), (2, 3), (3, 1))
print(top_3_three_grams) # ((1, 2, 3), (2, 3, 1), (1, 4, 5))
```

Если на вход подается некорректное значение, возвращается пустой кортеж.

**Интерфейс**:
```py
class LanguageProfile:
  ...
  def get_top_k_n_grams(self, k: int, trie_level: int) -> tuple:
      pass
```

### Шаг 6.3. Подсчитать расстояние между двумя языковыми профилями 

Функция принимает на вход неизвестный и известный языковые профили, а также
параметр `k` - кол-во частотных N-грамм и `trie_level` - тип N-грамм (биграмма, триграмма и т.д.).

Функция получает наборы частотных N-грамм из языковых профилей.
Функция сравнивает наборы частотных N-грамм у двух языковых профилей.

Правило подсчёта расстояния:
* Для каждой N-граммы из первого кортежа находится соответствующая N-грамма
  во втором кортеже.
* Расстояние между ними рассчитывается как модуль разности индексов.
* Если N-грамма отсутствует во втором кортеже, расстояние равняется длине второго кортежа.
* Все полученные расстояния суммируются.

Например, первый набор частотных N-грамм - `first_n_grams = ((1, 2), (4, 5), (2, 3))`,
второй набор – `second_n_grams = ((1, 2), (2, 3), (4, 5))`. Расстояние для `(1, 2)` равно `0`,
так как индекс в первом наборе – `0`, во втором – `0`, `|0 – 0| = 0`. Расстояние для `(4, 5)` равно `1`,
расстояние для `(2, 3)` равно `1`. Соответственно расстояние между наборами равно `2`.

Если на вход подаются некорректные значения, возвращается -1.

**Интерфейс**:
```py
def calculate_distance(unknown_profile: LanguageProfile, 
                       known_profile: LanguageProfile, 
                       k: int, trie_level: int) -> tuple:
    pass
```

### Шаг 6.4. Подсчитать расстояние между неизвестным профилем и известными профилями (Выполнение шагов 5-6.4 соответствует 6 баллам)

Вам необходимо подсчитать расстояние между профилем для неизвестного языка:
```
UNKNOWN_SAMPLE = "Helium is material."
```
И профилями английского и немецкого языков, построенных на текстах:
```
ENG_SAMPLE = "Helium is the byproduct of millennia of radioactive decay from the elements thorium and uranium."
GERMAN_SAMPLE = "Zwei Begriffe, die nicht unbedingt zueinander passen, am Arbeitsplatz schon mal gar nicht."
```
Расстояние от неизвестного профиля для каждого из известных профилей
необходимо сравнить с полученными нами расстояниями в переменной `EXPECTED_DISTANCE_TO_EN_DE_PROFILES`.

Все вычисления и вызовы функций производятся в файле `start.py`:
```
# score 6, params: k = 5, trie_level = 2
# print(calculate_distance(unknown_profile, en_profile, 5, 2))
# print(calculate_distance(unknown_profile, de_profile, 5, 2))
EXPECTED_DISTANCE_TO_EN_DE_PROFILES = 17, 25 
```

### Шаг 7. Создать структуру для детектирования языков

Класс `LanguageDetector` позволяет определить язык произвольного текста на основе текстов на известных языках.

Конструктор не принимает никакие параметры при инициализации экземпляра класса `languageDetector`.

Однако, у конструктора есть в последствии заполняемое поле `self.profiles`,
в котором хранятся зарегистрированные языковые профили.

**Интерфейс**:
```py
class LanguageDetector:
    pass
```

### Шаг 7.1. Зарегистрировать языковой профиль в детекторе

После инициализации экземпляра детектора `LanguageDetector` его можно
насытить языковыми профилями на известных языках.

Метод принимает на вход экземпляр класса `LanguageProfile`, представляющий
конкретный языковой профиль.

Метод добавляет языковой профиль в детектор. Каждый языковой профиль 
добавляется в поле класса `self.language_profiles`, которое представляет
из себя словарь, с ключом - меткой языка, а значением - соответствующим языковым профилем.

Если метод успешно зарегистрировал языковой профиль, то возвращается `0`,
в противном случае возвращается `1`.

Например, для закодированного текста и языкового профиля по этому тексту:
```py
print(encoded_text)  # (((1, 2, 3, 1), (1, 4, 5, 1), (1, 2, 6, 7, 7, 8, 1)),)
print(en_profile)  # <__main__.LanguageProfile object at 0x0A0794D8>
```
Будет зарегистрирован следующий профиль в классе `LanguageDetector`:
```py
print(en_profile.language_profiles)  # {'en': <__main__.LanguageProfile object at 0x0A0794D8>}
```

**Интерфейс**:
```py
class LanguageDetector:
  ...
  def register_language(self, language_profile: LanguageProfile) -> int:
    pass
```

### Шаг 7.2. Определить язык текста

Метод принимает на вход языковой профиль класса `LanguageProfile` для неизвестного языка `unknown_profile`, 
а также параметр `k`, который означает количество частотных N-грамм для сравнения
и параметр `trie_levels` - кортеж с одним элементом числом, 
который обозначает размерность N-грамм, участвующих в сравнении.

Метод возвращает словарь, где ключом является язык, а значением – расстояние.

Язык определяется по расстоянию между `k` N-грамм языковых профилей.
Чем меньше расстояние, тем вероятнее тот или иной язык.

Находятся расстояния между `k` N-грамм для известных языковый профилей из словаря `language_profiles`
и `k` N-грамм из языкового профиля на неизвестном языке.

Если расстояние между `k` N-грамм из английского и неизвестного профилей равно `7`,
а расстояние между `k` N-грамм из немецкого и неизвестного профилей равно `12`,
то метод вернет словарь типа: `{'en': 12, 'de': 7}`.

Если на вход подаются некорректные значения, возвращается `-1`.

**Интерфейс**:
```py
class LanguageDetector:
  ...
  def detect(self, unknown_profile: LanguageProfile, k: int, trie_levels: int) -> Dict[str, int] or int:
      pass
```

### Шаг 8. Сохранить языковой профиль

Если постоянно запускать детектор и всегда заново создавать языковые профили,
это может занять много времени и вычислительных ресурсов. Созданный единожды языковой
профиль можно сохранить. Для этого у класса `LanguageProfile` должен появиться метод,
который сможет корректно сохранять языковой профиль.

Метод принимает на вход название `name` языкового профиля с `.json` расширением,
например, `eng_profile.json`. 

Метод сохраняет профиль из поля класса `profile` в формате `.json` в 
текущую рабочую директорию. 

Метод возвращает `0`, если сохранение прошло успешно и `1` в противном случае.

- **Обратите внимание, что в классе `LanguageProfile` языковой профиль хранится в закодированном виде, тогда как
в записанном файле представлены декодированные буквы.**
- **Для сохранения профиля в формате `.json` необходимо не просто декодировать N-граммы, но и перевести их в
строковый формат, с которым работает `.json`, иначе вам не удастся сохранить профиль. То есть условная биграмма `(2, 3)` должна
быть декодирована из кортежа и записана в виде одной строки, например, `"am"`**
- **При работе с `.json` файлами рекомендуется использовать модуль `json`.**

Например, профиль английского языка собранный из текста `Programming` с полями:
```py
en_profile = LanguageProfile(letter_storage_object, 'en')
print(en_profile.language)  # en
print(en_profile.tries)  # [<__main__.NGramTrie object at 0x09B37E50>, <__main__.NGramTrie object at 0x09B37EB0>]
print(en_profile.n_words)  # [9, 12]
```
И следующими частотами (униграмм и бирамм):
```py
print(new_en_profile.tries[0].n_gram_frequencies)  # {(1,): 2, (2,): 1, (3,): 2, (4,): 1, (5,): 2, (6,): 1, (7,): 2, (8,): 1, (9,): 1}
print(new_en_profile.tries[1].n_gram_frequencies)  # {(1, 2): 1, (2, 3): 1, (3, 4): 1, (4, 5): 1, (5, 3): 1, (3, 6): 1, (6, 7): 1, (7, 7): 1, (7, 8): 1, (8, 9): 1, (9, 5): 1, (5, 1): 1}
```
Должен будет сохраниться в файл `en_profile.json` и выглядеть
в файле следующим образом (например, для униграмм и биграмм):
```py
{
  "freq": {
    "a": 1, "g": 2, "_": 2, "i": 1,
    "m": 2, "n": 1, "o": 1, "p": 1, "r": 2,
    "_p": 1, "am": 1, "g_": 1, "in": 1,
    "gr": 1, "mi": 1, "mm": 1, "ng": 1,
    "og": 1, "pr": 1, "ra": 1, "ro": 1
  },
  "n_words": [
    9,
    12
  ],
  "name": "en"
}
```

Чтобы воспользоваться функцией `json.dump` или `json.dumps`, нужно передать туда словарь. 
То есть нужно по существующему профилю построить словарь заданного формата.
Шаблон для открытия и записи в файл с использованием модуля `json`:
```py
with open('name_of_profile_to_save', 'w') as file:
    json_string = json.dumps(profile_as_dict)
    file.write(json_string)
```

**Интерфейс**:
```py
class LanguageProfile:
  ...
  def save(self, name: str) -> int:
      pass
```

### Шаг 8.1. Собрать N-граммы и частоты из заданного словаря

Расширим функционал класса `NGramTrie` для того, чтобы
он смог заполняться N-граммами из словаря.

Метод принимает на вход словарь N-грамм и их частот.

Метод проверяет заданный словарь на корректность, а затем заполняет
поле `self.n_gram_frequencies` соответствующими N-граммами и их частотами. 

Если заполнение прошло успешно, метод возвращает `0`,
в противном случае метод возвращает `1`.

**Интерфейс**:
```py
class NGramTrie:
  ...
  def extract_n_grams_frequencies(self, n_grams_dictionary: dict) -> int:
      pass
```

### Шаг 8.2. Открыть языковой профиль (Выполнение Шагов 7-8.2 соответствует 8 баллам)

Теперь нам понадобится метод, который сможет открыть сохраненный
прежде языковой профиль.

Метод принимает на вход название файла `name` языкового профиля с расширением,
например, `eng_profile.json`, который лежит в текущей директории.

**Обратите внимание**: Сохраненный профиль нужно адаптировать к классу `LanguageProfile`.

Метод открывает профиль и заполняет соответствующие поля класса `LanguageProfile`.

Метод возвращает `0`, если открытие прошло успешно и `1` в противном случае.

Алгоритм работы с открываемым профилем выглядит следующим образом:

1. При открытии профиля, его название по ключу `['name']` и количество N-грамм
разных размерностей по ключу `['n_words']` записываются в поля класса `self.language` 
и `self.n_words` соответственно.
2. Для корректного открытия поля `['freq']` необходимо разделить все представленные N-граммы
по ключу `['freq']` на размерности, например, в одну группу должны попасть все биграммы,
во вторую группу все триграммы и так далее в зависимости от заданного словаря.
3. Все N-граммы из словаря языкового профиля должны быть добавлены в ваше хранилище букв
класса `LetterStorage`, лежащего в поле `self.storage` для того, чтобы провести корректную кодировку букв.
4. N-граммы в каждой группе должны быть закодированы и превращены в кортежи, с которыми уже
будет работать ваша программа. Например, для словаря биграмм `{'_a': 12, 'ab': 40}`
у вас должен получится словарь с соответствующими закодированными биграммами: 
`{(1, 2): 12, (2, 3): 40}`. Для остальных размерностей также.
5. Далее, под каждую группу-размерность N-грамм, например, под все биграммы должен
быть создан экземпляр класса `NGramTrie`, который нужно заполнить закодированными биграммами
и их частотами с использованием метода `extract_n_gram_frequencies`. Каждый экземпляр
класса `NGramTrie` помещается, соответственно, в поле языкового профиля `self.tries`. 

Например, при открытии профиля `profile.json` 
со следующим содержимым:
```py
{
  "freq": {
    "a": 1, "g": 2, "_": 2, "i": 1,
    "m": 2, "n": 1, "o": 1, "p": 1, "r": 2,
    "_p": 1, "am": 1, "g_": 1, "in": 1,
    "gr": 1, "mi": 1, "mm": 1, "ng": 1,
    "og": 1, "pr": 1, "ra": 1, "ro": 1
  },
  "n_words": [
    9,
    12
  ],
  "name": "en"
}
```
В экземпляре класса `LanguageProfile` `en_profile` должны заполнится следующие поля:
```py
en_profile.open('profile.json')
print(en_profile.language)  # en
print(en_profile.tries)  # [<__main__.NGramTrie object at 0x09B37E50>, <__main__.NGramTrie object at 0x09B37EB0>]
print(en_profile.n_words)  # [9, 12]
```
Каждый экземпляр класса `NGramTrie` из поля `self.tries` должен
иметь следующие униграммы и биграммы в полях `self.n_gram_frequencies`:
```py
print(new_en_profile.tries[0].n_gram_frequencies)  # {(1,): 2, (2,): 1, (3,): 2, (4,): 1, (5,): 2, (6,): 1, (7,): 2, (8,): 1, (9,): 1}
print(new_en_profile.tries[1].n_gram_frequencies)  # {(1, 2): 1, (2, 3): 1, (3, 4): 1, (4, 5): 1, (5, 3): 1, (3, 6): 1, (6, 7): 1, (7, 7): 1, (7, 8): 1, (8, 9): 1, (9, 5): 1, (5, 1): 1}
```

Шаблон для открытия и чтения из файла с использованием модуля `json`:
```py
with open(profile_file, 'r') as lang_profile_file:
    profile_dict = json.load(lan_profile_file)
    print(profile_dict['name'])  # 'en'
    # your code goes here
```

**Интерфейс**:
```py
class LanguageProfile:
  ...
  def open(self, file_name: str) -> int:
      pass
```

### Шаг 8.3. Продемонстрировать работу программы-детектора (Выполнение Шагов 7-8.3 соответствует 8 баллам)

Вам даны три текста:
```py
ENG_SAMPLE = "Helium is the byproduct of millennia of radioactive decay from the elements thorium and uranium."
GERMAN_SAMPLE = "Zwei Begriffe, die nicht unbedingt zueinander passen, am Arbeitsplatz schon mal gar nicht."
UNKNOWN_SAMPLE = "Helium is material."
```

Вся работа проводится в файле `start.py`.

Вам необходимо: 

1. Создать языковые профили класса `LanguageProfile`: `en_profile`, `de_profile`, `unknown` для трех заданных текстов.
2. Сохранить профиль на неизвестном языке `unknown` в файл `unknown_profile.json`.
3. Открыть тот же профиль `unknown_profile.json` на неизвестном языке в новый профиль класса `LanguageProfile` `profile_unk`.
4. Провести детектирование неизвестного языка из открытого профиля, сравнив его с профилями английского и немецкого языков.

**Обратите внимание**: Параметры для запуска функций для этого задания даны в файле `start.py`:
```py
# score 8, k = 5, trie_level = 3
# print(detector.detect(profile_unk, 5, 3))
# EXPECTED_SCORE = {'en': 24, 'de': 25}
```

### Шаг 9. Создать дополнительную структуру классификатора языков

Класс `ProbabilityLanguageDetector` наследуется от класса `LanguageDetector`
и позволяет определить язык неизвестного языкового профиля на основе вероятности того,
что данный профиль относится к тому или иному известному языковому профилю.

Дополнительная инициализация конструктора не требуется.

**Интерфейс**:
```py
class ProbabilityLanguageDetector(LanguageDetector):
  pass
```

### Шаг 9.1. Расчитать лог-вероятности для каждой N-граммы

Для работы с вероятностями, нам необходимо расширить функционал 
существующего класса `NGramTrie` новым методом `calculate_log_probabilities`.

Метод рассчитывает лог-вероятности N-грамм используя поле `n_grams_frequencies`.
Метод заполняет поле `n_gram_log_probabilities`.

Формула расчета вероятности для биграмм: 

<img src="https://latex.codecogs.com/gif.latex?P(w_{n}|w_{n-1})&space;=&space;\frac{C(w_{n-1},w_{n})}{\sum_{w}C(w_{n-1},&space;w)}" title="P(w_{n}|w_{n-1}) = \frac{C(w_{n-1},w_{n})}{\sum_{w}C(w_{n-1}, w)}" />

<img src="https://latex.codecogs.com/gif.latex?C(w_{n}|w_{n-1})" title="C(w_{n}|w_{n-1})" /> - это количество появлений кортежа 

<img src="https://latex.codecogs.com/gif.latex?(w_{n-1},&space;w_{n})" title="(w_{n-1}, w_{n})" /> 
в заданном тексте (частота).

<img src="https://latex.codecogs.com/gif.latex?\sum_{w}{C(w_{n-1},&space;w)}" title="\sum_{w}{C(w_{n-1}, w)}" /> - это 
количество появлений кортежей вида 

<img src="https://latex.codecogs.com/gif.latex?(w_{n-1}&space;w)" title="(w_{n-1} w)" />
для всех `w` в заданном корпусе.

Идея проста: насколько часто биграмма, начинающаяся с буквы
<img src="https://latex.codecogs.com/gif.latex?w_{n-1}" title="w_{n-1}" />
будет заканчиваться интересующей
нас буквой 
<img src="https://latex.codecogs.com/gif.latex?w_{n}" title="w_{n}" />.

Формула расчета вероятности для N-грамм:

<img src="https://latex.codecogs.com/gif.latex?P(w_{n}|w_{n-1},w_{n-2},...,w_{n-N&plus;1})&space;=&space;\frac{C(w_{n-N&plus;1},&space;...,&space;w_{n-1},&space;w_{n})}{\sum_{w}C(w_{n-N&plus;1},&space;...,&space;w_{n-1},&space;w)}" title="P(w_{n}|w_{n-1},w_{n-2},...,w_{n-N+1}) = \frac{C(w_{n-N+1}, ..., w_{n-1}, w_{n})}{\sum_{w}C(w_{n-N+1}, ..., w_{n-1}, w)}" />

После получения относительных вероятностей (описаны выше), необходимо взять логарифм по 
основанию `e` (натуральный логарифм)
от полученного отношения. В рамках текущей работы, это просто требование - оперировать лог-вероятностями.

Все значения вероятностей хранятся в поле `n_gram_log_probabilities`.

Если добавление прошло успешно, возвращается `0`.
Если на вход подается некорректное значение, возвращается `1`

Например,
```py
self.n_gram_log_probabilities[(1,2)] = -7.072576102542302
```

Интерфейс:

```py
class NGramTrie:
  ...
  def calculate_log_probabilities(self) -> int:
    pass
```

### Шаг 9.2. Собрать N-граммы и лог-вероятности из заданного словаря

Расширим функционал класса `NGramTrie` для того, чтобы
он смог заполняться N-граммами и лог-вероятностями из словаря.

Метод принимает на вход словарь N-грамм и их лог-вероятностей.

Метод проверяет заданный словарь на корректность, а затем заполняет
поле `self.n_gram_log_probabilities` соответствующими N-граммами и их лог-вероятностями. 

Если заполнение прошло успешно, метод возвращает `0`,
в противном случае метод возвращает `1`.

**Интерфейс**:
```py
class NGramTrie:
  ...
  def extract_n_grams_log_probabilities(self, n_grams_dictionary: dict) -> int:
      pass
``` 

### Шаг 10. Расчитать вероятность принадлежности набора N-грамм языковому профилю

Функция сравнивает наборы лог-вероятностей N-грамм у двух языковых профилей.
Функция принимает на вход языковой профиль, язык которого нужно детектировать,
а также один известный языковой профиль, на основе которого будет считаться вероятность.
Помимо профилей, функция принимает также параметр `k` - количество частотных N-грамм, которые
будут участвовать в сравнении, а также `trie_level` - размерность N-грамм (например, биграммы).

Функция возвращает вероятность того, что неизвестный языковой профиль принадлежит известному языковому профилю.

Функция считает принадлежность N-грамм по заданному уровню `trie_level`. 
Вероятность для заданных N-грамм рассчитывается как сумма лог-вероятностей всех N-грамм, 
которые присутствуют в заданном известном языковом профиле. Например, если биграмма `(1, 2)`
из неизвестного языкового профиля
есть в известном языковом профиле, то мы добавляем лог-вероятность этой биграммы из известного
профиля к общей лог-вероятности и так далее для топ `k` частотных N-грамм, которые присутствуют в 
`unknown_profile`.

Если на вход подаются некорректные значения, возвращается `-1`.

Интерфейс:
```py
def calculate_probability(unknown_profile: LanguageProfile, known_profile: LanguageProfile,
                               k: int, trie_level: int) -> float or int:
      pass
```

### Шаг 10.1. Классифицировать неизвестный языковой профиль по вероятности 

Метод принимает на вход языковой профиль на неизвестном языке `unknown_profile`, 
а также параметр `k` - число частотных N-грамм для участия в подсчете вероятности
и параметр `trie_levels`, который обозначает размерности N-грамм, участвующих в сравнении. 

Метод возвращает словарь, где ключом является язык и размерность, значением – вероятность. Чем дальше итоговая
вероятность от 0, тем более вероятен такой язык для неизвестного языкового профиля.

Пример словаря:
```py
{
 ('en', 2): -7.072576102542302,
 ('de', 2): -12.012676864542572
}
```
В данном случае, для неизвестного языкового профиля были использованы
биграммы для детектирования языка. Неизвестный профиль сравнивался с профилем
английского и немецкого языков.

Метод подсчитывает вероятность принадлежности неизвестного языкового профиля 
одному из известных языковых профилей на основании вероятности входящих 
в известные языковые профили частотных N-грамм из неизвестного языкового профиля.
Для подсчета вероятности используется метод `calculate_probability`.

Если на вход подаются некорректные значения, возвращается значение `-1`.

Например, при обработки следующих двух предложений:
```py
print(text_en)  # 'Helium is the byproduct of millennia of radioactive decay from the elements thorium and uranium.'
print(text_de)  # 'Zwei Begriffe, die nicht unbedingt zueinander passen, am Arbeitsplatz schon mal gar nicht.'
```
И детектировании языка третьего предложения на основе языковых профилей по первым двум предложениям:
```py
print(text_unk)  # 'Helium is material.'
```
Получается следующий результат:
```py
print(output)  # {
    ('en', 1): -28.966986289527135, 
    ('de', 1): -30.49674625841781, 
    ('en', 2): -12.570715759118084, 
    ('de', 2): -0.6931471805599453, 
    ('en', 3): -1.791759469228055, 
    ('de', 3): 0.0
}
```

Интерфейс:
```py
class ProbabilityLanguageDetector(LanguageDetector):
  ... 
  def detect(self, unknown_profile: LanguageProfile, k: int, trie_levels: tuple) -> Dict[Tuple[str, int], int or float] or int:
      pass
```

### Шаг 10.2. Предсказать экзотический язык (Выполнение Шагов 9-10.2 соответствует 10 баллам)

Вам даны предложения на экзотическом языке:
```
Некој е болен и тој не е слободен. 
Dлетува гол во дупка од мраз. 
И пее, а плаче од болка. 
Дали е ова контраст, можеби – живот?
```

Необходимо использовать написанные классы и функции для предсказания языка неизвестного экзотического языка,
а также поиска минимального расстояния между профилем экзотического и профилем одного из известных языков.

Необходимые языковые профили (30 шт.) лежат в гугл диске по ссылке: 
https://drive.google.com/drive/folders/1ZwZeYUNdk7H9-hORlmqih82rT_0drd6Q?usp=sharing.
Профили представляют из себя унифицированные по заданному стандарту файлы `.json`.
Ваша программа также может открывать эти профили и предсказывать язык неизвестного текста,
основываясь на стандартных профилях, подготовленных исследователями в индустрии. 
Вам необходимо их скачать и положить в папку `profiles`. Далее можно проводить детектирование.

Структура папки `lab_3`:
```
|-- lab_3
    |-- profiles
    |-- __init__.py
    |-- main.py
    |-- start.py
    |-- *_test.py
    |-- sample_profile.json
    |-- lab_3.md
```

Вам необходимо в файле `start.py` открыть все профили и провести детектирование неизвестного языка,
проставить полученные результаты детектирования в переменные `EXPECTED_LANGUAGE` - метка языка,
которую предсказала ваша программа, а также `EXPECTED_MIN_DISTANCE` - минимальное расстояние
профиля для экзотического языка и профиля, для которого была получена предсказанная метка.
Параметры и функции, которые нужно вызвать для проверки, находятся также в `start.py`.

### Ссылки

* [Репозиторий с официальными языковыми профилями](https://github.com/shuyo/language-detection)
* [Полезный ресурс для пытливых умов](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
* [Что такое лог-вероятности и зачем они нужны](https://en.wikipedia.org/wiki/Log_probability)

